# Steps to extract the data

so far, the script seems to find all tables, and it looks like it won't be too difficult to deal with it. However, not all tables are directly mapped in the first attempts.

The procedure for the next time should be:

* write detailed extraction procedure for each table
* write the tables to txt files (or html), maybe even with some background-script for navigation between tables
* check for things not matched between the meta-file with concepts and the table data
* find reason for missing 10+x tables
* identify problems of mis-matches, like wrong chars, etc.

 
